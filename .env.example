# Model and API Configuration
# ------------------------------
# Base URL for API endpoint
# For OpenAI: https://api.openai.com/v1
# For OpenRouter: https://api.openrouter.ai/v1
# For Ollama: http://localhost:11434/v1
BASE_URL=https://api.openai.com/v1

# API keys
# For OpenAI or OpenRouter API key (when not using Ollama)
LLM_API_KEY=your_openai_or_openrouter_api_key

# OpenAI API key (required for embeddings even when using Ollama for generation)
OPENAI_API_KEY=your_openai_api_key

# Azure OpenAI API Keys and Endpoints
AZURE_OPENAI_API_KEY=your_azure_api_key
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/

AZURE_OPENAI_O1_DEPLOYMENT=o1
AZURE_OPENAI_O3_DEPLOYMENT=o3-mini
AZURE_OPENAI_API_VERSION=2024-12-01-preview

AZURE_OPENAI_EMBEDDING_ENDPOINT=https://your-resource.openai.azure.com/openai/deployments/text-embedding-3-small
AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-3-small
AZURE_OPENAI_EMBEDDING_API_VERSION=2023-05-15

# AWS Bedrock
AWS_DEFAULT_REGION=us-east-1
AWS_ACCESS_KEY_ID=your_aws_access_key
AWS_SECRET_ACCESS_KEY=your_aws_secret_key

AWS_CLAUDE_HAIKU_MODEL=anthropic.claude-3-haiku-20240307-v1:0
AWS_CLAUDE_SONNET_MODEL=us.anthropic.claude-3-7-sonnet-20250219-v1:0
AWS_FALLBACK_MODEL=arn:aws:bedrock:us-east-1:637423531635:inference-profile/us.anthropic.claude-3-7-sonnet-20250219-v1:0

# GCP
VERTEXAI_PROJECT=your_gcp_project_id
VERTEXAI_LOCATION=us-east5
GCP_GEMINI_PRO_MODEL=gemini-1.5-pro-002
GCP_GEMINI_FLASH_MODEL=gemini-1.5-flash-002
GCP_CLAUDE_MODEL=claude-3-5-sonnet-v2@20241022

GEMINI_API_KEY=your_gemini_api_key

# Rapid API Key
RAPID_API_KEY=your_rapid_api_key

# Financial Modeling Prep API Key
FINANCIAL_MODELING_PREP_API_KEY=your_financial_modeling_prep_api_key

# Postgres
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=memory_db
POSTGRES_HOST=localhost
POSTGRES_PORT=5432

# Supabase (required for vector search)
SUPABASE_URL=your_supabase_url
SUPABASE_KEY=your_supabase_anon_key

# Application Configuration
# ------------------------------
# Directory for workbench files
WORKBENCH_DIR=workbench

# Default chunk size for document processing (in characters)
DEFAULT_CHUNK_SIZE=5000

# Maximum concurrent requests during crawling
MAX_CONCURRENT_REQUESTS=5

# AWS Configuration (if needed)
# ------------------------------
# AWS_ACCESS_KEY_ID=your_aws_access_key
# AWS_SECRET_ACCESS_KEY=your_aws_secret_key
# AWS_REGION=us-west-2
